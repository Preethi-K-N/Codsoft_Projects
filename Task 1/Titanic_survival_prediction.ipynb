{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Import necessary libraries"
      ],
      "metadata": {
        "id": "8EyxhHc8MKnV"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wmpKQi5VK_eb"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Load the Dataset"
      ],
      "metadata": {
        "id": "wUa2aHtvMx43"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the file name\n",
        "file_name = 'Titanic-Dataset.csv'\n",
        "\n",
        "# Load the dataset\n",
        "try:\n",
        "    df = pd.read_csv(\"/content/Titanic-Dataset.csv\")\n",
        "    print(f\"Successfully loaded '{file_name}'.\")\n",
        "\n",
        "    # Display the first 5 rows to check the data\n",
        "    print(\"\\n--- Data Head ---\")\n",
        "    print(df.head())\n",
        "\n",
        "    # Display info about columns and missing values\n",
        "    print(\"\\n--- Data Info ---\")\n",
        "    df.info()\n",
        "\n",
        "except FileNotFoundError:\n",
        "    print(f\"Error: The file '{file_name}' was not found.\")\n",
        "    print(\"Please make sure you have uploaded the file to Colab.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KvMXBiG6Mp8V",
        "outputId": "b81dcde7-06ab-4cdd-e0bf-c180aad7ce34"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Successfully loaded 'Titanic-Dataset.csv'.\n",
            "\n",
            "--- Data Head ---\n",
            "   PassengerId  Survived  Pclass  \\\n",
            "0            1         0       3   \n",
            "1            2         1       1   \n",
            "2            3         1       3   \n",
            "3            4         1       1   \n",
            "4            5         0       3   \n",
            "\n",
            "                                                Name     Sex   Age  SibSp  \\\n",
            "0                            Braund, Mr. Owen Harris    male  22.0      1   \n",
            "1  Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n",
            "2                             Heikkinen, Miss. Laina  female  26.0      0   \n",
            "3       Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1   \n",
            "4                           Allen, Mr. William Henry    male  35.0      0   \n",
            "\n",
            "   Parch            Ticket     Fare Cabin Embarked  \n",
            "0      0         A/5 21171   7.2500   NaN        S  \n",
            "1      0          PC 17599  71.2833   C85        C  \n",
            "2      0  STON/O2. 3101282   7.9250   NaN        S  \n",
            "3      0            113803  53.1000  C123        S  \n",
            "4      0            373450   8.0500   NaN        S  \n",
            "\n",
            "--- Data Info ---\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 891 entries, 0 to 890\n",
            "Data columns (total 12 columns):\n",
            " #   Column       Non-Null Count  Dtype  \n",
            "---  ------       --------------  -----  \n",
            " 0   PassengerId  891 non-null    int64  \n",
            " 1   Survived     891 non-null    int64  \n",
            " 2   Pclass       891 non-null    int64  \n",
            " 3   Name         891 non-null    object \n",
            " 4   Sex          891 non-null    object \n",
            " 5   Age          714 non-null    float64\n",
            " 6   SibSp        891 non-null    int64  \n",
            " 7   Parch        891 non-null    int64  \n",
            " 8   Ticket       891 non-null    object \n",
            " 9   Fare         891 non-null    float64\n",
            " 10  Cabin        204 non-null    object \n",
            " 11  Embarked     889 non-null    object \n",
            "dtypes: float64(2), int64(5), object(5)\n",
            "memory usage: 83.7+ KB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Preprocessing - Handle Missing Data"
      ],
      "metadata": {
        "id": "2SsjAMlKNPt_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. Handle Missing 'Age'\n",
        "median_age = df['Age'].median()\n",
        "df['Age'] = df['Age'].fillna(median_age)\n",
        "print(f\"Filled missing 'Age' values with median: {median_age}\")\n",
        "\n",
        "# 2. Handle Missing 'Embarked'\n",
        "mode_embarked = df['Embarked'].mode()[0]\n",
        "df['Embarked'] = df['Embarked'].fillna(mode_embarked)\n",
        "print(f\"Filled missing 'Embarked' values with mode: '{mode_embarked}'\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3iuIJpwTNTr6",
        "outputId": "c4ea0be3-1795-4f4a-b1d2-27c928a4ec82"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Filled missing 'Age' values with median: 28.0\n",
            "Filled missing 'Embarked' values with mode: 'S'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Preprocessing - Feature Engineering & Cleanup"
      ],
      "metadata": {
        "id": "iCW7K1IeNbSi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 3. Drop Unnecessary Columns\n",
        "columns_to_drop = ['PassengerId', 'Name', 'Ticket', 'Cabin']\n",
        "df = df.drop(columns=columns_to_drop)\n",
        "print(f\"Dropped columns: {columns_to_drop}\")\n",
        "\n",
        "# 4. Encode Categorical Variables\n",
        "df = pd.get_dummies(df, columns=['Sex', 'Embarked'], drop_first=True)\n",
        "print(\"Converted 'Sex' and 'Embarked' to numerical columns.\")\n",
        "\n",
        "# Check the final preprocessed data\n",
        "print(\"\\n--- Preprocessed Data Head ---\")\n",
        "print(df.head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ON_n5DgVNe8f",
        "outputId": "244c5ff2-ef4d-46ae-f0bd-d3e02dd2d4ca"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dropped columns: ['PassengerId', 'Name', 'Ticket', 'Cabin']\n",
            "Converted 'Sex' and 'Embarked' to numerical columns.\n",
            "\n",
            "--- Preprocessed Data Head ---\n",
            "   Survived  Pclass   Age  SibSp  Parch     Fare  Sex_male  Embarked_Q  \\\n",
            "0         0       3  22.0      1      0   7.2500      True       False   \n",
            "1         1       1  38.0      1      0  71.2833     False       False   \n",
            "2         1       3  26.0      0      0   7.9250     False       False   \n",
            "3         1       1  35.0      1      0  53.1000     False       False   \n",
            "4         0       3  35.0      0      0   8.0500      True       False   \n",
            "\n",
            "   Embarked_S  \n",
            "0        True  \n",
            "1       False  \n",
            "2        True  \n",
            "3        True  \n",
            "4        True  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Define Features (X) and Target (y)"
      ],
      "metadata": {
        "id": "sLMUr12EN25b"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 'X' contains all our feature columns\n",
        "X = df.drop('Survived', axis=1)\n",
        "\n",
        "# 'y' is our target variable\n",
        "y = df['Survived']\n",
        "\n",
        "print(\"Features (X):\", X.columns.tolist())\n",
        "print(\"Target (y): 'Survived'\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NYytgEE1N6SV",
        "outputId": "6b8e8c42-29ec-4c50-bb06-0510a3fabc99"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Features (X): ['Pclass', 'Age', 'SibSp', 'Parch', 'Fare', 'Sex_male', 'Embarked_Q', 'Embarked_S']\n",
            "Target (y): 'Survived'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Split Data into Training and Testing Sets"
      ],
      "metadata": {
        "id": "3T1aUS4QN984"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "print(f\"Data split into {len(X_train)} training samples and {len(X_test)} testing samples.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vp7JKfJOOBGo",
        "outputId": "efa036f9-0329-41f5-db6d-8289d35d1e1d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Data split into 712 training samples and 179 testing samples.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Feature Scaling"
      ],
      "metadata": {
        "id": "5XDNamvaOEw2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "scaler = StandardScaler()\n",
        "\n",
        "# Fit the scaler ONLY on the training data\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "\n",
        "# Transform both the training and testing data\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "print(\"Features have been scaled.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ldu_NuPDOGs_",
        "outputId": "34170c73-8de7-47e8-823f-44ea3342a5e4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Features have been scaled.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Train the Model"
      ],
      "metadata": {
        "id": "jXAkh0GYOKvI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize the model\n",
        "model = LogisticRegression(random_state=42)\n",
        "\n",
        "# Train the model\n",
        "model.fit(X_train_scaled, y_train)\n",
        "\n",
        "print(\"Model training complete.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Zo5xMC5kONe_",
        "outputId": "44e37a08-2678-4900-c7e3-b5cc2c666398"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model training complete.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Evaluate the Model"
      ],
      "metadata": {
        "id": "YWugck-FOQBv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Make predictions on the test set\n",
        "y_pred = model.predict(X_test_scaled)\n",
        "\n",
        "# 1. Calculate and print accuracy\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(f\"\\n--- Model Accuracy ---\")\n",
        "print(f\"{accuracy:.4f} (or {accuracy*100:.2f}%)\")\n",
        "\n",
        "# 2. Print Confusion Matrix\n",
        "print(\"\\n--- Confusion Matrix ---\")\n",
        "# [[True Negatives,  False Positives],\n",
        "#  [False Negatives, True Positives]]\n",
        "print(confusion_matrix(y_test, y_pred))\n",
        "\n",
        "# 3. Print Classification Report\n",
        "print(\"\\n--- Classification Report ---\")\n",
        "print(classification_report(y_test, y_pred))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hiOUgbzjOSHU",
        "outputId": "b3ba82b2-8386-411e-9e9c-7c3669522a9f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Model Accuracy ---\n",
            "0.8101 (or 81.01%)\n",
            "\n",
            "--- Confusion Matrix ---\n",
            "[[90 15]\n",
            " [19 55]]\n",
            "\n",
            "--- Classification Report ---\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.83      0.86      0.84       105\n",
            "           1       0.79      0.74      0.76        74\n",
            "\n",
            "    accuracy                           0.81       179\n",
            "   macro avg       0.81      0.80      0.80       179\n",
            "weighted avg       0.81      0.81      0.81       179\n",
            "\n"
          ]
        }
      ]
    }
  ]
}